---
title: 'CSDA1010SUMA18 - LAB EXERCISE 3: Classification Problem'
output:
  pdf_document: default
  html_notebook: default
  html_document:
    df_print: paged
---


```{r message=FALSE, warning=FALSE}
library(readr)
library(dplyr)
library(ggplot2)
library(rpart)
library(rpart.plot)
library(Amelia)
library(rattle)
library(RColorBrewer)
library(caret)
```

# Nursery Data Set reference and short description

Source: http://archive.ics.uci.edu/ml/datasets/Nursery

```
| class values

not_recom, recommend, very_recom, priority, spec_prior

| attributes

parents:     usual, pretentious, great_pret.
has_nurs:    proper, less_proper, improper, critical, very_crit.
form:        complete, completed, incomplete, foster.
children:    1, 2, 3, more.
housing:     convenient, less_conv, critical.
finance:     convenient, inconv.
social:      nonprob, slightly_prob, problematic.
health:      recommended, priority, not_recom.
```


```{r message=FALSE, warning=FALSE}
nursery_data <- read.csv("http://archive.ics.uci.edu/ml/machine-learning-databases/nursery/nursery.data", header = FALSE, col.names = c("parents","has_nurs","form","children","housing","finance","social","health","class"))

# nursery_data <- read.csv(file = "../data/nursery_data.csv")
```

# Data Set exploration and cleaning
```{r message=FALSE, warning=FALSE}
set.seed(77)
dim(nursery_data)
#head(nursery_data)
#str(nursery_data)

```

## Coding for categorical variables

## Reorder factors

Very often, especially when plotting data, we need to reorder the levels of a factor because the default order is alphabetical. A direct way of reordering, using standard syntax is as follows.

Current levels, need to be corrected to correspont to the dataset description
```{r}
print (levels(nursery_data$parents))
print (levels(nursery_data$has_nurs))
print (levels(nursery_data$form))
print (levels(nursery_data$children))
print (levels(nursery_data$housing))
print (levels(nursery_data$finance))
print (levels(nursery_data$social))
print (levels(nursery_data$health))
print (levels(nursery_data$class))
```

Correction:
```{r}
nursery_data$parents <- factor(nursery_data$parents,levels(nursery_data$parents)[c(3,2,1)])
nursery_data$has_nurs <- factor(nursery_data$has_nurs,levels(nursery_data$has_nurs)[c(4,3,2,1,5)])
nursery_data$form <- factor(nursery_data$form,levels(nursery_data$form)[c(1,2,4,3)])
nursery_data$children <- factor(nursery_data$children,levels(nursery_data$children)[c(1,2,3,4)])
nursery_data$housing <- factor(nursery_data$housing,levels(nursery_data$housing)[c(1,3,2)])
nursery_data$finance <- factor(nursery_data$finance,levels(nursery_data$finance)[c(1,2)])
nursery_data$social <- factor(nursery_data$social,levels(nursery_data$social)[c(1,3,2)])
nursery_data$health <- factor(nursery_data$health,levels(nursery_data$health)[c(1,3,2)])
nursery_data$class <- factor(nursery_data$class,levels(nursery_data$class)[c(1,3,5,2,4)])
```

Corrected levels, now correspond to the dataset description
```{r}
print (levels(nursery_data$parents))
print (levels(nursery_data$has_nurs))
print (levels(nursery_data$form))
print (levels(nursery_data$children))
print (levels(nursery_data$housing))
print (levels(nursery_data$finance))
print (levels(nursery_data$social))
print (levels(nursery_data$health))
print (levels(nursery_data$class))
```

## Convert to numbers in one step
[Ref] (https://stackoverflow.com/questions/47922184/convert-categorical-variables-to-numeric-in-r)
```{r}
data <- data.matrix(nursery_data)
head(data)
```

## Preparing scaled data
```{r}
#index <- sample(1:nrow(data),round(0.75*nrow(data)))
#index <- createDataPartition(y= data$QLT, p=0.5, list = FALSE)
maxs <- apply(data, 2, max) 
mins <- apply(data, 2, min)
scaled <- as.data.frame(scale(data, center = mins, scale = maxs - mins))
#train_ <- scaled[index,]
#test_ <- scaled[-index,]
```

# The problem

## Distribution of target value in the dataset
The target value class of the wine quality is not equally distributed. The Figure \ref{fig:hist_class} demonstrates the distribution. As we can see, dataset covers mostly medium-quality wines with QLT between 5 and 7 well, low and high  quality wines represented poorly.
```{r}
prop.table(table(nursery_data$class))
```


```{r hist_class, fig.pos = 'h', fig.height=3, fig.width=5, fig.align="center", fig.cap="Distribution the Target 'class' Attribute in the Nursery Dataset"}
ggplot(data = nursery_data, mapping = aes(x = class)) + geom_bar()
```

# Clustering

A fundamental question is how to determine the value of the parameter k. 
If we looks at the percentage of variance explained as a function of the number of clusters: 
One should choose a number of clusters so that adding another cluster doesn't give much better 
modeling of the data. More precisely, if one plots the percentage of variance explained by the 
clusters against the number of clusters, the first clusters will add much information 
(explain a lot of variance), but at some point the marginal gain will drop, 
giving an angle in the graph. The number of clusters is chosen at this point, hence the 'elbow criterion'.

```{r}
wssplot <- function(data, nc=15, seed=1234){
  wss <- (nrow(data)-1)*sum(apply(data,2,var))
  for (i in 2:nc){
    set.seed(seed)
    wss[i] <- sum(kmeans(data, centers=i)$withinss)}
  plot(1:nc, wss, type="b", xlab="Number of Clusters",
       ylab="Within groups sum of squares")}

wssplot(scaled, nc=15) 
```

## Clustering using K-means method
```{r  fig.height=10, fig.width=10}
set.seed(420)
clusters_num =5
k.means.fit <- kmeans(scaled, clusters_num,iter.max = 1000)
# attributes(k.means.fit)
k.means.fit$centers
# plot(k.means.fit$centers[,c("RS","ALC")])
# k.means.fit$cluster
k.means.fit$size
```


```{r fig.height=10, fig.width=10}
library(cluster)
clusplot(scaled, k.means.fit$cluster, main='2D representation of the Cluster solution',
         color=TRUE, shade=FALSE,
         labels=clusters_num, lines=0)
```

# Explain clusters

## Explain by 'class' 

Let's try to explain clusters by the 'class'. Code below builds a matrix whe columns are cluster numbers and rows are target classes.

```{r}
table(nursery_data$class,k.means.fit$cluster)
```

# Hierarchical Clustering

Hierarchical methods uses a distance matrix as an input for the clustering algorithm. 
The choice of an appropriate metric will influence the shape of the clusters, as some element
may be close to one another according to one distance and farther away according to another.
We use the Euclidean distance as an input for the clustering algorithm 
ward.2D minimum variance criterion minimizes the total within-cluster variance:

```{r}
d <- dist(scaled, method = "manhattan")
H.fit <- hclust(d, method="ward.D2")
```

The clustering output can be displayed in a dendrogram

```{r dendr, fig.hight=8, fig.width=8}
clusters_num = 20
plot(H.fit)
groups <- cutree(H.fit, k=clusters_num)
rect.hclust(H.fit, k=clusters_num, border="red") 
```

The clustering performance can be evaluated with the aid of a confusion matrix as follows. Let's look at the groups that have mixed valued of 'class'. Group 1 contains class 'recommend' and also 'very_recom' and 'priority'. Since our idea is relable rows to 'recommend' to increase it's presense, let's check if there is any justification to do this.


```{r}
table(nursery_data$class,groups)
```

Let's find what are the most significant factors that separate group 1 from also mixed group 5. It looks that group has better financial situation but 22% less favorable family structure and 12% better housing situation, with the rest of the attributes beeing close - less that 1%. We could arbitrary decide that it is justified to downgade group 1 grading all the fows to 'recommend' even thogh most of the rows were previously been labeled higher.

```{r}
dif <- colMeans(scaled[groups == 1,]) - colMeans(scaled[groups == 5,])
dif <- dif[order(abs(dif), decreasing = T)]
print(dif)
```

Group 5 has high amount of 'very_recommend' values in addition to 'priority' and some 'special_priority'. Let's find what are the most significant factors that separate group 5 from also mixed similar group 9. Looking at the most influential attribus defining the difference between those groups, it looks that group 5 has less favorable financial situation, but 50% better housing situation and 30% better formal family structure. Again we could arbitrary decide that it is justified to downgrade group 5 down grading all the records in the group as 'very_recommend' even though most of the rows were previously been labeled higher.

```{r}
dif <- colMeans(scaled[groups == 5,]) - colMeans(scaled[groups == 9,])
dif <- dif[order(abs(dif), decreasing = T)]
print(dif)
```

Lets fix the groups 1 and 5 by relabelling class according to our conclusions:

```{r}
nursery_data[groups == 1,]$class<- 'recommend'
nursery_data[groups == 5,]$class<- 'very_recom'
```

Lets analyze the result visualizing the distribution of class now. Obviosly  the distribution is improved compaired to previous data.  

```{r}
prop.table(table(nursery_data$class))
```
```{r hist2_class, fig.pos = 'h', fig.height=3, fig.width=5, fig.align="center", fig.cap="Distribution the Target 'class' Attribute in the Nursery Dataset"}
ggplot(data = nursery_data, mapping = aes(x = class)) + geom_bar()
```

# Modeling

## Random Forest model prediction and evaluation of the original dataset

The Nursery dataset has been split in such a way that train and test sets would have the same distribution of the 'class' attribute. The reason for this stratification strategy is to focus on the priority of an applicants placement in a nursery school rather than an applicants family or social status. We used 75:25 split ratio. 

```{r}
train.rows<- createDataPartition(y= nursery_data$class, p=0.75, list = FALSE)
train.data<- nursery_data[train.rows,]
prop.table((table(train.data$class)))
```

```{r}
test.data<- nursery_data[-train.rows,]
prop.table((table(test.data$class)))
```

```{r message=FALSE, warning=FALSE}
library(randomForest)
fitRF2 <- randomForest(
  class~parents+has_nurs+form+children+housing+finance+social+health,
  method="anova",
  data=train.data, importance=TRUE, ntree=1000 )
```

Now let's calculate prediction and it's evaluation using the corrected dataset. As we expected, now all but one of the "very_recom" values of the target "class" attribute were predicted correctly which led to total accuracy of the prediction to 98% with overall balanced precision accross all the predicted "class" values.

```{r}
PredictionRF2 <- predict(fitRF2, test.data)
confMat2 <- table(PredictionRF2,test.data$class)
confMat2
accuracy <- sum(diag(confMat2))/sum(confMat2)
cat(sprintf("\nAccuracy=%f", accuracy))
```

To visualize the results of the predictions, the code below generates a scatter plot of the Predictor vs Test values (Figure \ref{fig:plot_rf_rw}). Also a QQ-Plot for Studentized Residuals is generated and presented in Figure \ref{fig:qq_rf_rw}.

```{r plot_rf_rw, fig.width=5.5, fig.align="center", message=FALSE, warning=FALSE, paged.print=FALSE, fig.cap="Random Forest Prediction"}
library(ggplot2)
df2 = data.frame(test.data$class, PredictionRF2)
colnames(df2) <- c("Test","Prediction")
ggplot(df2, aes(x = Test, y = Prediction)) +
        geom_jitter(width = 0.2, pch=20, col=rgb(0.1, 0.2, 0.8, 0.3))
```

# Neural Networks Prediction

[source](https://datascienceplus.com/fitting-neural-network-in-r/)

## Preparing scaled data
```{r}
set.seed(4231)
data <- data.matrix(nursery_data)
index <- sample(1:nrow(data),round(0.75*nrow(data)))
#index <- createDataPartition(y= data$QLT, p=0.5, list = FALSE)
maxs <- apply(data, 2, max) 
mins <- apply(data, 2, min)
scaled <- as.data.frame(scale(data, center = mins, scale = maxs - mins))
train_ <- scaled[index,]
test_ <- scaled[-index,]
```

```{r}
library(neuralnet)
n <- names(train_)
f <- as.formula(paste("class ~", paste(n[!n %in% "class"], collapse = " + ")))
f
nn <- neuralnet(f,data=train_,hidden=c(5),linear.output=F)

```

```{r plot_nn, fig.height=9, fig.width=6, message=FALSE, warning=FALSE, fig.cap="Graphical representation of the NN model with the weights on each connection"}
plot(nn)
```

## Predicting using neural networks

NN outputs a normalized prediction, so we need to scale it back in order to make a meaningful comparison (or just a simple prediction)

```{r}
pr.nn <- compute(nn,test_[,1:8])
pr.nn_ <- pr.nn$net.result*(max(data$class)-min(data$class))+min(data$class)
test.r <- (test_$class)*(max(data$class)-min(data$class))+min(data$class)
SE.nn <- sum((test.r - pr.nn_)^2)/nrow(test_)
```

```{r}
cor(test.r,pr.nn_)
table(round(pr.nn_),as.factor(test.r))
```

```{r plot_rf2_rw, fig.width=5.5, fig.align="center", message=FALSE, warning=FALSE, paged.print=FALSE, fig.cap="SVM Prediction"}
library(ggplot2)
df2 = data.frame(as.factor(test.r), pr.nn_)
colnames(df2) <- c("Test","Prediction")
ggplot(df2, aes(x = Test, y = Prediction)) +
        geom_boxplot(outlier.colour = "red") +
        geom_jitter(width = 0.25, pch=20, col=rgb(0.1, 0.2, 0.8, 0.3))
```

